# Care-tuning, another way to fine-tune language models

## Code

The GPT training code in this repository is mostly taken from the excellent [nanoGPT](https://github.com/karpathy/nanoGPT), originally written by Andrej Karpathy, with minor modifications and extensions. The license for the original code can be found in the LICENSES folder.

## Data

## Activities

Your system will train on different types of activities, linked to different input and output formats. At present time, activities can be:

* observation
* reading
* skill-training
* hearing conversations
* having conversations
* experimenting
* thinking
* dreaming

Different types of data will be suited to one or more of these activities. For instance, the Visual Genome data is good for *observing* and *skill-training*.
